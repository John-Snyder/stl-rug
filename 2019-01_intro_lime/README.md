By: Matt Dube

The lime package provides a method to explain the predictions of black box models by fitting a local model around perturbations of the predictions.

I plan to present an overview of the package that will focus on the idea of local interpretation of model predictions versus global interpretation of the same model. I will also cover some common use cases and options.

I will discuss some limitations of the method used by the lime package, and alternative packages that are doing similar things regarding model interpretation and explanation.

I will walk through a 'live' demo using a couple of small data sets.

Scripts are in [01_Scripts/](01_Scripts/) and are numbered; run in order. You can start with [01_demo_prep.R](01_Scripts/01_demo_prep.R) if you don't care about the model training or data loading, and you download all directories.
