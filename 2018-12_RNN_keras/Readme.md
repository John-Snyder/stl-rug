By: John Snyder

Keras is a high level API which interfaces with deep learning frameworks such as Tensorflow. It's modularity allows for a vast amount of network types to be implemented as "building blocks" through the functions provided in the associated R package.

Specifically, a Recurrent Neural Network (RNN) is a network which builds on standard neural nets by introducing additional "memory" connections in order to allow sequential data to be efficiently processed as input.

In this presentation, I will first briefly go over the R-Keras installation process for both CPU and GPU configurations as well as provide a high level overview of an RNN and LSTM (Long Short-Term Memory) network. The modeling demonstration will then show how to build single layer and stacked recurrent networks and apply them to a range of simple to complex examples.

Overall, participants should walk away appreciating the power of recurrent networks for the processing of sequential data as well as the flexibility of the Keras library for facilitating quick experimentation.
